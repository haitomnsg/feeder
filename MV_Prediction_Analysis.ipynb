{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e58e3b7f",
   "metadata": {},
   "source": [
    "# Megawatt (MW) Prediction Using Machine Learning and Deep Learning Models\n",
    "\n",
    "## Project Overview\n",
    "This notebook implements a comprehensive analysis and prediction system for Megawatt (MW) consumption using various machine learning and deep learning models.\n",
    "\n",
    "### Models Implemented:\n",
    "- **Machine Learning**: SVR, Random Forest, XGBoost\n",
    "- **Deep Learning**: LSTM, GRU\n",
    "\n",
    "### Evaluation Metrics:\n",
    "- RMSE (Root Mean Square Error)\n",
    "- MAPE (Mean Absolute Percentage Error)\n",
    "- MAE (Mean Absolute Error)\n",
    "- MSE (Mean Square Error)\n",
    "- R-squared"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42da7bfd",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2673eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Machine Learning Libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Deep Learning Libraries\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, GRU, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Evaluation Metrics\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "print('All libraries imported successfully!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e412865",
   "metadata": {},
   "source": [
    "## 2. Load and Explore Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfadd056",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_excel('combinedMVWeatherData/combinedMVWeather.xlsx')\n",
    "\n",
    "# Display basic information\n",
    "print('Dataset Shape:', df.shape)\n",
    "print('\\nFirst few rows:')\n",
    "print(df.head())\n",
    "print('\\nDataset Info:')\n",
    "print(df.info())\n",
    "print('\\nStatistical Summary:')\n",
    "print(df.describe())\n",
    "print('\\nMissing Values:')\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f3600c",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e3db72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a copy of the dataset\n",
    "data = df.copy()\n",
    "\n",
    "# Convert Time column to datetime\n",
    "data['Time'] = pd.to_datetime(data['Time'])\n",
    "\n",
    "# Handle missing values in MW column\n",
    "print(f'Missing MW values before: {data[\"MW\"].isnull().sum()}')\n",
    "\n",
    "# Fill missing MW values using interpolation\n",
    "data['MW'] = data['MW'].interpolate(method='linear')\n",
    "\n",
    "# If any remaining NaN values, use forward fill then backward fill\n",
    "data['MW'].fillna(method='ffill', inplace=True)\n",
    "data['MW'].fillna(method='bfill', inplace=True)\n",
    "\n",
    "print(f'Missing MW values after: {data[\"MW\"].isnull().sum()}')\n",
    "\n",
    "# Extract time-based features\n",
    "data['Hour'] = data['Time'].dt.hour\n",
    "data['Day'] = data['Time'].dt.day\n",
    "data['Month'] = data['Time'].dt.month\n",
    "data['DayOfWeek'] = data['Time'].dt.dayofweek\n",
    "data['DayOfYear'] = data['Time'].dt.dayofyear\n",
    "\n",
    "# Create cyclical features for hour\n",
    "data['Hour_sin'] = np.sin(2 * np.pi * data['Hour'] / 24)\n",
    "data['Hour_cos'] = np.cos(2 * np.pi * data['Hour'] / 24)\n",
    "\n",
    "# Create cyclical features for month\n",
    "data['Month_sin'] = np.sin(2 * np.pi * data['Month'] / 12)\n",
    "data['Month_cos'] = np.cos(2 * np.pi * data['Month'] / 12)\n",
    "\n",
    "print('\\nFeatures after preprocessing:')\n",
    "print(data.columns.tolist())\n",
    "print('\\nData shape after feature engineering:', data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f85436a",
   "metadata": {},
   "source": [
    "## 4. Exploratory Data Analysis (EDA) and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42726a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of MW (target variable)\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "axes[0].hist(data['MW'], bins=50, edgecolor='black', alpha=0.7)\n",
    "axes[0].set_title('Distribution of MW', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('MW')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "\n",
    "axes[1].boxplot(data['MW'])\n",
    "axes[1].set_title('Box Plot of MW', fontsize=14, fontweight='bold')\n",
    "axes[1].set_ylabel('MW')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f'MW Statistics:')\n",
    "print(f'Mean: {data[\"MW\"].mean():.2f}')\n",
    "print(f'Median: {data[\"MW\"].median():.2f}')\n",
    "print(f'Std Dev: {data[\"MW\"].std():.2f}')\n",
    "print(f'Min: {data[\"MW\"].min():.2f}')\n",
    "print(f'Max: {data[\"MW\"].max():.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315ee80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time series plot of MW\n",
    "plt.figure(figsize=(20, 6))\n",
    "plt.plot(data['Time'], data['MW'], linewidth=0.5, alpha=0.8)\n",
    "plt.title('MW Consumption Over Time', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Time', fontsize=12)\n",
    "plt.ylabel('MW', fontsize=12)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a6d1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MW consumption by hour of day\n",
    "plt.figure(figsize=(14, 6))\n",
    "hourly_avg = data.groupby('Hour')['MW'].mean()\n",
    "plt.bar(hourly_avg.index, hourly_avg.values, alpha=0.7, edgecolor='black')\n",
    "plt.title('Average MW Consumption by Hour of Day', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Hour of Day', fontsize=12)\n",
    "plt.ylabel('Average MW', fontsize=12)\n",
    "plt.xticks(range(24))\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b18f8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MW consumption by month\n",
    "plt.figure(figsize=(12, 6))\n",
    "monthly_avg = data.groupby('Month')['MW'].mean()\n",
    "plt.bar(monthly_avg.index, monthly_avg.values, alpha=0.7, edgecolor='black', color='coral')\n",
    "plt.title('Average MW Consumption by Month', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Month', fontsize=12)\n",
    "plt.ylabel('Average MW', fontsize=12)\n",
    "plt.xticks(range(1, 13))\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1170e879",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation heatmap\n",
    "plt.figure(figsize=(12, 8))\n",
    "numeric_cols = ['MW', 'Air Temperature', 'Global Solar Radiation', 'Relative Humidity', 'Hour', 'Month', 'DayOfWeek']\n",
    "correlation_matrix = data[numeric_cols].corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, fmt='.2f', square=True)\n",
    "plt.title('Correlation Matrix of Features', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed77a391",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relationship between MW and weather features\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# MW vs Temperature\n",
    "axes[0].scatter(data['Air Temperature'], data['MW'], alpha=0.5, s=1)\n",
    "axes[0].set_title('MW vs Air Temperature', fontsize=12, fontweight='bold')\n",
    "axes[0].set_xlabel('Air Temperature')\n",
    "axes[0].set_ylabel('MW')\n",
    "\n",
    "# MW vs Solar Radiation\n",
    "axes[1].scatter(data['Global Solar Radiation'], data['MW'], alpha=0.5, s=1, color='orange')\n",
    "axes[1].set_title('MW vs Solar Radiation', fontsize=12, fontweight='bold')\n",
    "axes[1].set_xlabel('Global Solar Radiation')\n",
    "axes[1].set_ylabel('MW')\n",
    "\n",
    "# MW vs Humidity\n",
    "axes[2].scatter(data['Relative Humidity'], data['MW'], alpha=0.5, s=1, color='green')\n",
    "axes[2].set_title('MW vs Relative Humidity', fontsize=12, fontweight='bold')\n",
    "axes[2].set_xlabel('Relative Humidity')\n",
    "axes[2].set_ylabel('MW')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6daeaeb1",
   "metadata": {},
   "source": [
    "## 5. Prepare Data for Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475ab931",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features for ML models\n",
    "feature_cols = ['Air Temperature', 'Global Solar Radiation', 'Relative Humidity', \n",
    "                'Hour', 'Day', 'Month', 'DayOfWeek', 'DayOfYear',\n",
    "                'Hour_sin', 'Hour_cos', 'Month_sin', 'Month_cos']\n",
    "\n",
    "X = data[feature_cols].values\n",
    "y = data['MW'].values\n",
    "\n",
    "# Split data into training and testing sets (80-20 split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=False)\n",
    "\n",
    "print(f'Training set size: {X_train.shape[0]} samples')\n",
    "print(f'Testing set size: {X_test.shape[0]} samples')\n",
    "print(f'Number of features: {X_train.shape[1]}')\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print('\\nData scaling completed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba62002",
   "metadata": {},
   "source": [
    "## 6. Machine Learning Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6494b6",
   "metadata": {},
   "source": [
    "### 6.1 Support Vector Regression (SVR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5997d2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training SVR model...')\n",
    "svr_model = SVR(kernel='rbf', C=100, gamma='scale', epsilon=0.1)\n",
    "svr_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predictions\n",
    "svr_train_pred = svr_model.predict(X_train_scaled)\n",
    "svr_test_pred = svr_model.predict(X_test_scaled)\n",
    "\n",
    "print('SVR model trained successfully!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c527af6c",
   "metadata": {},
   "source": [
    "### 6.2 Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0584144c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training Random Forest model...')\n",
    "rf_model = RandomForestRegressor(n_estimators=200, max_depth=20, min_samples_split=5, \n",
    "                                  min_samples_leaf=2, random_state=42, n_jobs=-1)\n",
    "rf_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predictions\n",
    "rf_train_pred = rf_model.predict(X_train_scaled)\n",
    "rf_test_pred = rf_model.predict(X_test_scaled)\n",
    "\n",
    "print('Random Forest model trained successfully!')\n",
    "\n",
    "# Feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': feature_cols,\n",
    "    'Importance': rf_model.feature_importances_\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(feature_importance['Feature'], feature_importance['Importance'])\n",
    "plt.xlabel('Importance')\n",
    "plt.title('Random Forest Feature Importance', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a39ddb5",
   "metadata": {},
   "source": [
    "### 6.3 XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7d9e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training XGBoost model...')\n",
    "xgb_model = XGBRegressor(n_estimators=200, learning_rate=0.1, max_depth=10, \n",
    "                         min_child_weight=1, subsample=0.8, colsample_bytree=0.8,\n",
    "                         random_state=42, n_jobs=-1)\n",
    "xgb_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predictions\n",
    "xgb_train_pred = xgb_model.predict(X_train_scaled)\n",
    "xgb_test_pred = xgb_model.predict(X_test_scaled)\n",
    "\n",
    "print('XGBoost model trained successfully!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1fa9902",
   "metadata": {},
   "source": [
    "## 7. Deep Learning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e392823c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for deep learning models (sequence format)\n",
    "def create_sequences(X, y, time_steps=24):\n",
    "    X_seq, y_seq = [], []\n",
    "    for i in range(len(X) - time_steps):\n",
    "        X_seq.append(X[i:i + time_steps])\n",
    "        y_seq.append(y[i + time_steps])\n",
    "    return np.array(X_seq), np.array(y_seq)\n",
    "\n",
    "# Use MinMaxScaler for deep learning models\n",
    "scaler_dl = MinMaxScaler()\n",
    "X_train_dl = scaler_dl.fit_transform(X_train)\n",
    "X_test_dl = scaler_dl.transform(X_test)\n",
    "\n",
    "# Create sequences (using 24-hour lookback)\n",
    "time_steps = 24\n",
    "X_train_seq, y_train_seq = create_sequences(X_train_dl, y_train, time_steps)\n",
    "X_test_seq, y_test_seq = create_sequences(X_test_dl, y_test, time_steps)\n",
    "\n",
    "print(f'Training sequences shape: {X_train_seq.shape}')\n",
    "print(f'Testing sequences shape: {X_test_seq.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d804f2cb",
   "metadata": {},
   "source": [
    "### 7.1 LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f2a860",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Building LSTM model...')\n",
    "\n",
    "# Build LSTM model\n",
    "lstm_model = Sequential([\n",
    "    LSTM(128, activation='relu', return_sequences=True, input_shape=(time_steps, X_train_seq.shape[2])),\n",
    "    Dropout(0.2),\n",
    "    LSTM(64, activation='relu', return_sequences=True),\n",
    "    Dropout(0.2),\n",
    "    LSTM(32, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "lstm_model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "print(lstm_model.summary())\n",
    "\n",
    "# Early stopping\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Train the model\n",
    "print('\\nTraining LSTM model...')\n",
    "lstm_history = lstm_model.fit(\n",
    "    X_train_seq, y_train_seq,\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[early_stop],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Predictions\n",
    "lstm_train_pred = lstm_model.predict(X_train_seq).flatten()\n",
    "lstm_test_pred = lstm_model.predict(X_test_seq).flatten()\n",
    "\n",
    "print('LSTM model trained successfully!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f598ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot LSTM training history\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "axes[0].plot(lstm_history.history['loss'], label='Training Loss')\n",
    "axes[0].plot(lstm_history.history['val_loss'], label='Validation Loss')\n",
    "axes[0].set_title('LSTM Model Loss', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1].plot(lstm_history.history['mae'], label='Training MAE')\n",
    "axes[1].plot(lstm_history.history['val_mae'], label='Validation MAE')\n",
    "axes[1].set_title('LSTM Model MAE', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('MAE')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c66b92b0",
   "metadata": {},
   "source": [
    "### 7.2 GRU Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc222204",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Building GRU model...')\n",
    "\n",
    "# Build GRU model\n",
    "gru_model = Sequential([\n",
    "    GRU(128, activation='relu', return_sequences=True, input_shape=(time_steps, X_train_seq.shape[2])),\n",
    "    Dropout(0.2),\n",
    "    GRU(64, activation='relu', return_sequences=True),\n",
    "    Dropout(0.2),\n",
    "    GRU(32, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "gru_model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "print(gru_model.summary())\n",
    "\n",
    "# Train the model\n",
    "print('\\nTraining GRU model...')\n",
    "gru_history = gru_model.fit(\n",
    "    X_train_seq, y_train_seq,\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[early_stop],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Predictions\n",
    "gru_train_pred = gru_model.predict(X_train_seq).flatten()\n",
    "gru_test_pred = gru_model.predict(X_test_seq).flatten()\n",
    "\n",
    "print('GRU model trained successfully!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e56bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot GRU training history\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "axes[0].plot(gru_history.history['loss'], label='Training Loss')\n",
    "axes[0].plot(gru_history.history['val_loss'], label='Validation Loss')\n",
    "axes[0].set_title('GRU Model Loss', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1].plot(gru_history.history['mae'], label='Training MAE')\n",
    "axes[1].plot(gru_history.history['val_mae'], label='Validation MAE')\n",
    "axes[1].set_title('GRU Model MAE', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('MAE')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5646295",
   "metadata": {},
   "source": [
    "## 8. Model Evaluation and Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0123ab1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation metrics functions\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "    \n",
    "    return {\n",
    "        'RMSE': rmse,\n",
    "        'MAE': mae,\n",
    "        'MSE': mse,\n",
    "        'R2': r2,\n",
    "        'MAPE': mape\n",
    "    }\n",
    "\n",
    "# Calculate metrics for all models\n",
    "results = {}\n",
    "\n",
    "# SVR\n",
    "results['SVR'] = {\n",
    "    'Train': calculate_metrics(y_train, svr_train_pred),\n",
    "    'Test': calculate_metrics(y_test, svr_test_pred)\n",
    "}\n",
    "\n",
    "# Random Forest\n",
    "results['Random Forest'] = {\n",
    "    'Train': calculate_metrics(y_train, rf_train_pred),\n",
    "    'Test': calculate_metrics(y_test, rf_test_pred)\n",
    "}\n",
    "\n",
    "# XGBoost\n",
    "results['XGBoost'] = {\n",
    "    'Train': calculate_metrics(y_train, xgb_train_pred),\n",
    "    'Test': calculate_metrics(y_test, xgb_test_pred)\n",
    "}\n",
    "\n",
    "# LSTM\n",
    "results['LSTM'] = {\n",
    "    'Train': calculate_metrics(y_train_seq, lstm_train_pred),\n",
    "    'Test': calculate_metrics(y_test_seq, lstm_test_pred)\n",
    "}\n",
    "\n",
    "# GRU\n",
    "results['GRU'] = {\n",
    "    'Train': calculate_metrics(y_train_seq, gru_train_pred),\n",
    "    'Test': calculate_metrics(y_test_seq, gru_test_pred)\n",
    "}\n",
    "\n",
    "print('Metrics calculated for all models!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa45836e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison table\n",
    "comparison_data = []\n",
    "for model_name, metrics in results.items():\n",
    "    comparison_data.append({\n",
    "        'Model': model_name,\n",
    "        'RMSE': metrics['Test']['RMSE'],\n",
    "        'MAE': metrics['Test']['MAE'],\n",
    "        'MSE': metrics['Test']['MSE'],\n",
    "        'R2': metrics['Test']['R2'],\n",
    "        'MAPE': metrics['Test']['MAPE']\n",
    "    })\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "comparison_df = comparison_df.sort_values('RMSE')\n",
    "\n",
    "print('\\n' + '='*80)\n",
    "print('MODEL PERFORMANCE COMPARISON (Test Set)')\n",
    "print('='*80)\n",
    "print(comparison_df.to_string(index=False))\n",
    "print('='*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b2d607",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize model comparison\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "metrics_list = ['RMSE', 'MAE', 'MSE', 'R2', 'MAPE']\n",
    "colors = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#FFA07A', '#98D8C8']\n",
    "\n",
    "for idx, metric in enumerate(metrics_list):\n",
    "    row = idx // 3\n",
    "    col = idx % 3\n",
    "    ax = axes[row, col]\n",
    "    \n",
    "    metric_values = [results[model]['Test'][metric] for model in results.keys()]\n",
    "    bars = ax.bar(results.keys(), metric_values, color=colors[idx], alpha=0.7, edgecolor='black')\n",
    "    \n",
    "    ax.set_title(f'{metric} Comparison', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel(metric)\n",
    "    ax.tick_params(axis='x', rotation=45)\n",
    "    ax.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{height:.3f}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "# Hide the last subplot\n",
    "axes[1, 2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31609519",
   "metadata": {},
   "source": [
    "## 9. Prediction Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e93e2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot predictions for ML models (showing first 500 test samples)\n",
    "n_samples = 500\n",
    "\n",
    "fig, axes = plt.subplots(3, 1, figsize=(18, 12))\n",
    "\n",
    "# SVR\n",
    "axes[0].plot(y_test[:n_samples], label='Actual', linewidth=2, alpha=0.8)\n",
    "axes[0].plot(svr_test_pred[:n_samples], label='SVR Prediction', linewidth=1.5, alpha=0.7)\n",
    "axes[0].set_title('SVR Predictions vs Actual', fontsize=14, fontweight='bold')\n",
    "axes[0].set_ylabel('MW')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Random Forest\n",
    "axes[1].plot(y_test[:n_samples], label='Actual', linewidth=2, alpha=0.8)\n",
    "axes[1].plot(rf_test_pred[:n_samples], label='Random Forest Prediction', linewidth=1.5, alpha=0.7)\n",
    "axes[1].set_title('Random Forest Predictions vs Actual', fontsize=14, fontweight='bold')\n",
    "axes[1].set_ylabel('MW')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# XGBoost\n",
    "axes[2].plot(y_test[:n_samples], label='Actual', linewidth=2, alpha=0.8)\n",
    "axes[2].plot(xgb_test_pred[:n_samples], label='XGBoost Prediction', linewidth=1.5, alpha=0.7)\n",
    "axes[2].set_title('XGBoost Predictions vs Actual', fontsize=14, fontweight='bold')\n",
    "axes[2].set_xlabel('Sample Index')\n",
    "axes[2].set_ylabel('MW')\n",
    "axes[2].legend()\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140ce0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot predictions for DL models\n",
    "fig, axes = plt.subplots(2, 1, figsize=(18, 10))\n",
    "\n",
    "# LSTM\n",
    "axes[0].plot(y_test_seq[:n_samples], label='Actual', linewidth=2, alpha=0.8)\n",
    "axes[0].plot(lstm_test_pred[:n_samples], label='LSTM Prediction', linewidth=1.5, alpha=0.7)\n",
    "axes[0].set_title('LSTM Predictions vs Actual', fontsize=14, fontweight='bold')\n",
    "axes[0].set_ylabel('MW')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# GRU\n",
    "axes[1].plot(y_test_seq[:n_samples], label='Actual', linewidth=2, alpha=0.8)\n",
    "axes[1].plot(gru_test_pred[:n_samples], label='GRU Prediction', linewidth=1.5, alpha=0.7)\n",
    "axes[1].set_title('GRU Predictions vs Actual', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Sample Index')\n",
    "axes[1].set_ylabel('MW')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658f21e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare all models on same plot\n",
    "plt.figure(figsize=(20, 8))\n",
    "plt.plot(y_test[:n_samples], label='Actual', linewidth=2.5, alpha=0.9, color='black')\n",
    "plt.plot(svr_test_pred[:n_samples], label='SVR', linewidth=1, alpha=0.7)\n",
    "plt.plot(rf_test_pred[:n_samples], label='Random Forest', linewidth=1, alpha=0.7)\n",
    "plt.plot(xgb_test_pred[:n_samples], label='XGBoost', linewidth=1, alpha=0.7)\n",
    "plt.plot(lstm_test_pred[:n_samples], label='LSTM', linewidth=1, alpha=0.7)\n",
    "plt.plot(gru_test_pred[:n_samples], label='GRU', linewidth=1, alpha=0.7)\n",
    "plt.title('All Models Predictions Comparison', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Sample Index', fontsize=12)\n",
    "plt.ylabel('MW', fontsize=12)\n",
    "plt.legend(loc='best', fontsize=10)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99272fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plots: Actual vs Predicted\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "\n",
    "models_pred = [\n",
    "    ('SVR', svr_test_pred),\n",
    "    ('Random Forest', rf_test_pred),\n",
    "    ('XGBoost', xgb_test_pred),\n",
    "    ('LSTM', lstm_test_pred),\n",
    "    ('GRU', gru_test_pred)\n",
    "]\n",
    "\n",
    "for idx, (name, pred) in enumerate(models_pred):\n",
    "    row = idx // 3\n",
    "    col = idx % 3\n",
    "    ax = axes[row, col]\n",
    "    \n",
    "    if name in ['LSTM', 'GRU']:\n",
    "        y_actual = y_test_seq\n",
    "    else:\n",
    "        y_actual = y_test\n",
    "    \n",
    "    ax.scatter(y_actual, pred, alpha=0.5, s=10)\n",
    "    ax.plot([y_actual.min(), y_actual.max()], [y_actual.min(), y_actual.max()], \n",
    "            'r--', linewidth=2, label='Perfect Prediction')\n",
    "    ax.set_title(f'{name}: Actual vs Predicted', fontsize=12, fontweight='bold')\n",
    "    ax.set_xlabel('Actual MW')\n",
    "    ax.set_ylabel('Predicted MW')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Hide the last subplot\n",
    "axes[1, 2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b09cda",
   "metadata": {},
   "source": [
    "## 10. Interactive Prediction System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5779a9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_mw(air_temp, solar_radiation, humidity, hour, day, month, day_of_week, day_of_year, model='XGBoost'):\n",
    "    \"\"\"\n",
    "    Predict MW consumption based on input parameters\n",
    "    \n",
    "    Parameters:\n",
    "    - air_temp: Air Temperature (°C)\n",
    "    - solar_radiation: Global Solar Radiation (W/m²)\n",
    "    - humidity: Relative Humidity (%)\n",
    "    - hour: Hour of day (0-23)\n",
    "    - day: Day of month (1-31)\n",
    "    - month: Month (1-12)\n",
    "    - day_of_week: Day of week (0=Monday, 6=Sunday)\n",
    "    - day_of_year: Day of year (1-365)\n",
    "    - model: Model to use ('SVR', 'Random Forest', 'XGBoost', 'LSTM', 'GRU')\n",
    "    \n",
    "    Returns:\n",
    "    - Predicted MW value\n",
    "    \"\"\"\n",
    "    # Calculate cyclical features\n",
    "    hour_sin = np.sin(2 * np.pi * hour / 24)\n",
    "    hour_cos = np.cos(2 * np.pi * hour / 24)\n",
    "    month_sin = np.sin(2 * np.pi * month / 12)\n",
    "    month_cos = np.cos(2 * np.pi * month / 12)\n",
    "    \n",
    "    # Create feature array\n",
    "    features = np.array([[air_temp, solar_radiation, humidity, hour, day, month, \n",
    "                         day_of_week, day_of_year, hour_sin, hour_cos, month_sin, month_cos]])\n",
    "    \n",
    "    # Scale features\n",
    "    features_scaled = scaler.transform(features)\n",
    "    \n",
    "    # Make prediction based on selected model\n",
    "    if model == 'SVR':\n",
    "        prediction = svr_model.predict(features_scaled)[0]\n",
    "    elif model == 'Random Forest':\n",
    "        prediction = rf_model.predict(features_scaled)[0]\n",
    "    elif model == 'XGBoost':\n",
    "        prediction = xgb_model.predict(features_scaled)[0]\n",
    "    else:\n",
    "        print(f\"Note: {model} requires sequential data. Using XGBoost instead.\")\n",
    "        prediction = xgb_model.predict(features_scaled)[0]\n",
    "    \n",
    "    return prediction\n",
    "\n",
    "print('Prediction function created successfully!')\n",
    "print('\\nUsage example:')\n",
    "print('predict_mw(air_temp=15.0, solar_radiation=100, humidity=85, hour=14, day=15, month=6, day_of_week=2, day_of_year=166)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b735d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example predictions\n",
    "print('\\n' + '='*80)\n",
    "print('EXAMPLE PREDICTIONS')\n",
    "print('='*80)\n",
    "\n",
    "# Example 1: Morning, low solar radiation\n",
    "print('\\nExample 1: Morning (8 AM), Low Solar Radiation')\n",
    "pred1 = predict_mw(air_temp=15.0, solar_radiation=50, humidity=80, \n",
    "                   hour=8, day=15, month=6, day_of_week=2, day_of_year=166, model='XGBoost')\n",
    "print(f'Predicted MW: {pred1:.2f}')\n",
    "\n",
    "# Example 2: Afternoon, high solar radiation\n",
    "print('\\nExample 2: Afternoon (2 PM), High Solar Radiation')\n",
    "pred2 = predict_mw(air_temp=28.0, solar_radiation=800, humidity=45, \n",
    "                   hour=14, day=15, month=6, day_of_week=2, day_of_year=166, model='XGBoost')\n",
    "print(f'Predicted MW: {pred2:.2f}')\n",
    "\n",
    "# Example 3: Night, no solar radiation\n",
    "print('\\nExample 3: Night (10 PM), No Solar Radiation')\n",
    "pred3 = predict_mw(air_temp=18.0, solar_radiation=0, humidity=75, \n",
    "                   hour=22, day=15, month=6, day_of_week=2, day_of_year=166, model='XGBoost')\n",
    "print(f'Predicted MW: {pred3:.2f}')\n",
    "\n",
    "print('\\n' + '='*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f0ba8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive prediction interface\n",
    "print('\\n' + '='*80)\n",
    "print('INTERACTIVE MW PREDICTION SYSTEM')\n",
    "print('='*80)\n",
    "print('\\nEnter the following parameters to predict MW consumption:\\n')\n",
    "\n",
    "# You can uncomment and modify these lines for interactive input\n",
    "# air_temp = float(input('Air Temperature (°C): '))\n",
    "# solar_radiation = float(input('Global Solar Radiation (W/m²): '))\n",
    "# humidity = float(input('Relative Humidity (%): '))\n",
    "# hour = int(input('Hour (0-23): '))\n",
    "# day = int(input('Day of month (1-31): '))\n",
    "# month = int(input('Month (1-12): '))\n",
    "# day_of_week = int(input('Day of week (0=Mon, 6=Sun): '))\n",
    "# day_of_year = int(input('Day of year (1-365): '))\n",
    "# model_choice = input('Model (SVR/Random Forest/XGBoost): ') or 'XGBoost'\n",
    "\n",
    "# For demonstration, using default values\n",
    "air_temp = 20.0\n",
    "solar_radiation = 400\n",
    "humidity = 65\n",
    "hour = 12\n",
    "day = 15\n",
    "month = 6\n",
    "day_of_week = 2\n",
    "day_of_year = 166\n",
    "model_choice = 'XGBoost'\n",
    "\n",
    "print(f'\\nInput Parameters:')\n",
    "print(f'Air Temperature: {air_temp}°C')\n",
    "print(f'Solar Radiation: {solar_radiation} W/m²')\n",
    "print(f'Humidity: {humidity}%')\n",
    "print(f'Hour: {hour}')\n",
    "print(f'Day: {day}')\n",
    "print(f'Month: {month}')\n",
    "print(f'Day of Week: {day_of_week}')\n",
    "print(f'Day of Year: {day_of_year}')\n",
    "print(f'Model: {model_choice}')\n",
    "\n",
    "prediction = predict_mw(air_temp, solar_radiation, humidity, hour, day, month, \n",
    "                       day_of_week, day_of_year, model=model_choice)\n",
    "\n",
    "print(f'\\n{\"=\"*80}')\n",
    "print(f'PREDICTED MW CONSUMPTION: {prediction:.2f} MW')\n",
    "print(f'{\"=\"*80}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e44287",
   "metadata": {},
   "source": [
    "## 11. Summary and Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89717b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n' + '='*80)\n",
    "print('PROJECT SUMMARY')\n",
    "print('='*80)\n",
    "\n",
    "print('\\n1. Dataset:')\n",
    "print(f'   - Total samples: {len(data)}')\n",
    "print(f'   - Features: Air Temperature, Global Solar Radiation, Relative Humidity, Time-based features')\n",
    "print(f'   - Target: MW (Megawatt consumption)')\n",
    "print(f'   - Training samples: {X_train.shape[0]}')\n",
    "print(f'   - Testing samples: {X_test.shape[0]}')\n",
    "\n",
    "print('\\n2. Models Implemented:')\n",
    "print('   Machine Learning:')\n",
    "print('   - Support Vector Regression (SVR)')\n",
    "print('   - Random Forest Regressor')\n",
    "print('   - XGBoost Regressor')\n",
    "print('   Deep Learning:')\n",
    "print('   - LSTM (Long Short-Term Memory)')\n",
    "print('   - GRU (Gated Recurrent Unit)')\n",
    "\n",
    "print('\\n3. Best Performing Model:')\n",
    "best_model = comparison_df.iloc[0]\n",
    "print(f'   Model: {best_model[\"Model\"]}')\n",
    "print(f'   RMSE: {best_model[\"RMSE\"]:.4f}')\n",
    "print(f'   MAE: {best_model[\"MAE\"]:.4f}')\n",
    "print(f'   R²: {best_model[\"R2\"]:.4f}')\n",
    "print(f'   MAPE: {best_model[\"MAPE\"]:.2f}%')\n",
    "\n",
    "print('\\n4. Key Features Contributing to Predictions:')\n",
    "print('   - Hour of day (strong correlation with MW consumption)')\n",
    "print('   - Air Temperature')\n",
    "print('   - Global Solar Radiation')\n",
    "print('   - Month and seasonal patterns')\n",
    "\n",
    "print('\\n5. Evaluation Metrics Used:')\n",
    "print('   - RMSE: Root Mean Square Error')\n",
    "print('   - MAE: Mean Absolute Error')\n",
    "print('   - MSE: Mean Square Error')\n",
    "print('   - R²: R-squared (Coefficient of Determination)')\n",
    "print('   - MAPE: Mean Absolute Percentage Error')\n",
    "\n",
    "print('\\n' + '='*80)\n",
    "print('PROJECT COMPLETED SUCCESSFULLY!')\n",
    "print('='*80)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
